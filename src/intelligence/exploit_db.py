"""
Exploit Database Integration
Integrates with ExploitDB, Metasploit, and other exploit repositories
"""

import asyncio
import aiohttp
import json
import re
import csv
import io
from typing import Dict, List, Optional, Set, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import logging
from pathlib import Path

from .nvd_client import CVEData
from .prioritization import ExploitInfo, ExploitAvailability

logger = logging.getLogger(__name__)

@dataclass
class ExploitMatch:
    """Exploit match result"""
    exploit_info: ExploitInfo
    service_match: bool
    version_match: bool
    platform_match: bool
    confidence: float
    match_reasons: List[str]

@dataclass
class ExploitSearchResult:
    """Exploit search result"""
    total_exploits: int
    high_confidence_matches: List[ExploitMatch]
    medium_confidence_matches: List[ExploitMatch]
    low_confidence_matches: List[ExploitMatch]
    search_summary: Dict

class ExploitDatabase:
    """
    Exploit Database Integration
    Searches and matches exploits from multiple sources
    """

    def __init__(self, cache_dir: str = "data/cache"):
        """
        Initialize exploit database

        Args:
            cache_dir: Directory for caching exploit data
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        # Exploit sources configuration
        self.sources = {
            'exploitdb': {
                'csv_url': 'https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv',
                'base_url': 'https://www.exploit-db.com/exploits/',
                'reliability': 0.8
            },
            'github': {
                'api_url': 'https://api.github.com/search/repositories',
                'reliability': 0.6
            },
            'packetstorm': {
                'search_url': 'https://packetstormsecurity.com/search/',
                'reliability': 0.7
            }
        }

        self.session = None
        self.exploitdb_cache = None

    async def __aenter__(self):
        """Async context manager entry"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=60),
            headers={'User-Agent': 'PenTestFramework/1.0'}
        )
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit"""
        if self.session:
            await self.session.close()

    def _get_cache_path(self, cache_key: str) -> Path:
        """Get cache file path"""
        return self.cache_dir / f"exploitdb_{cache_key}.json"

    def _is_cache_valid(self, cache_path: Path, ttl_hours: int = 24) -> bool:
        """Check if cache is valid"""
        if not cache_path.exists():
            return False

        import time
        file_age = time.time() - cache_path.stat().st_mtime
        return file_age < (ttl_hours * 3600)

    async def _load_exploitdb_csv(self) -> List[Dict]:
        """Load ExploitDB CSV data"""
        cache_path = self._get_cache_path("exploitdb_csv")

        # Try cache first
        if self._is_cache_valid(cache_path, ttl_hours=24):
            try:
                with open(cache_path, 'r') as f:
                    return json.load(f)
            except:
                pass

        # Download fresh data
        try:
            async with self.session.get(self.sources['exploitdb']['csv_url']) as response:
                if response.status == 200:
                    csv_content = await response.text()

                    # Parse CSV
                    csv_reader = csv.DictReader(io.StringIO(csv_content))
                    exploits = []

                    for row in csv_reader:
                        exploit = {
                            'id': row.get('id', ''),
                            'file': row.get('file', ''),
                            'description': row.get('description', ''),
                            'date': row.get('date', ''),
                            'author': row.get('author', ''),
                            'type': row.get('type', ''),
                            'platform': row.get('platform', ''),
                            'port': row.get('port', ''),
                            'tags': row.get('tags', '').split(';') if row.get('tags') else []
                        }
                        exploits.append(exploit)

                    # Cache the results
                    with open(cache_path, 'w') as f:
                        json.dump(exploits, f, indent=2)

                    return exploits
        except Exception as e:
            logger.error(f"Failed to load ExploitDB CSV: {e}")

        return []

    def _extract_cve_from_text(self, text: str) -> Set[str]:
        """Extract CVE IDs from text"""
        cve_pattern = r'CVE-\d{4}-\d{4,7}'
        return set(re.findall(cve_pattern, text, re.IGNORECASE))

    def _calculate_exploit_confidence(self, exploit: Dict, service_name: str,
                                    service_version: str, cve_id: str) -> Tuple[float, List[str]]:
        """
        Calculate confidence score for exploit match

        Args:
            exploit: Exploit data
            service_name: Target service name
            service_version: Target service version
            cve_id: CVE ID to match

        Returns:
            Tuple of (confidence score, match reasons)
        """
        confidence = 0.0
        reasons = []

        description = exploit.get('description', '').lower()
        tags = [tag.lower() for tag in exploit.get('tags', [])]

        # CVE match (highest confidence)
        if cve_id:
            exploit_cves = self._extract_cve_from_text(description)
            if cve_id.upper() in [cve.upper() for cve in exploit_cves]:
                confidence += 0.8
                reasons.append(f"CVE match: {cve_id}")

        # Service name match
        if service_name.lower() in description:
            confidence += 0.4
            reasons.append(f"Service match: {service_name}")

        # Version match
        if service_version and service_version in description:
            confidence += 0.3
            reasons.append(f"Version match: {service_version}")

        # Tag matches
        service_tags = [service_name.lower(), 'remote', 'exploit']
        for tag in tags:
            if tag in service_tags:
                confidence += 0.1
                reasons.append(f"Tag match: {tag}")

        # Platform relevance
        platform = exploit.get('platform', '').lower()
        if platform in ['multiple', 'linux', 'windows', 'unix']:
            confidence += 0.1
            reasons.append(f"Platform: {platform}")

        # Exploit type relevance
        exploit_type = exploit.get('type', '').lower()
        if 'remote' in exploit_type:
            confidence += 0.2
            reasons.append("Remote exploit")
        elif 'local' in exploit_type:
            confidence += 0.1
            reasons.append("Local exploit")

        return min(confidence, 1.0), reasons

    def _determine_exploit_availability(self, exploit: Dict) -> ExploitAvailability:
        """Determine exploit availability level"""
        description = exploit.get('description', '').lower()
        tags = [tag.lower() for tag in exploit.get('tags', [])]

        # Check for weaponized indicators
        weaponized_indicators = ['metasploit', 'msf', 'framework', 'automated']
        if any(indicator in description or indicator in tags for indicator in weaponized_indicators):
            return ExploitAvailability.WEAPONIZED

        # Check for functional exploit indicators
        functional_indicators = ['working', 'tested', 'verified', 'functional']
        if any(indicator in description for indicator in functional_indicators):
            return ExploitAvailability.FUNCTIONAL

        # Check for PoC indicators
        poc_indicators = ['poc', 'proof of concept', 'demonstration', 'example']
        if any(indicator in description for indicator in poc_indicators):
            return ExploitAvailability.POC

        # Default to functional if it's in ExploitDB
        return ExploitAvailability.FUNCTIONAL

    async def search_exploitdb(self, service_name: str, service_version: str = "",
                             cve_id: str = "") -> List[ExploitMatch]:
        """
        Search ExploitDB for matching exploits

        Args:
            service_name: Name of the service
            service_version: Version of the service
            cve_id: CVE ID to search for

        Returns:
            List of exploit matches
        """
        if not self.exploitdb_cache:
            self.exploitdb_cache = await self._load_exploitdb_csv()

        matches = []

        for exploit in self.exploitdb_cache:
            confidence, reasons = self._calculate_exploit_confidence(
                exploit, service_name, service_version, cve_id
            )

            if confidence > 0.2:  # Minimum threshold
                availability = self._determine_exploit_availability(exploit)

                exploit_info = ExploitInfo(
                    cve_id=cve_id,
                    exploit_id=exploit.get('id', ''),
                    source='exploitdb',
                    availability=availability,
                    reliability=self.sources['exploitdb']['reliability'],
                    complexity=self._assess_exploit_complexity(exploit),
                    description=exploit.get('description', ''),
                    references=[f"{self.sources['exploitdb']['base_url']}{exploit.get('id', '')}"],
                    last_updated=exploit.get('date', '')
                )

                match = ExploitMatch(
                    exploit_info=exploit_info,
                    service_match=service_name.lower() in exploit.get('description', '').lower(),
                    version_match=service_version in exploit.get('description', '') if service_version else False,
                    platform_match=True,  # ExploitDB has platform info
                    confidence=confidence,
                    match_reasons=reasons
                )

                matches.append(match)

        # Sort by confidence
        matches.sort(key=lambda m: m.confidence, reverse=True)
        return matches[:20]  # Limit results